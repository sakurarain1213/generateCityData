"""
DuckDB æç®€æŸ¥è¯¢æ¼”ç¤º & ç‰¹å¾æå–å·¥å…·
åŒ…å«ï¼š
1. æ€»ä½“ç»Ÿè®¡æŸ¥è¯¢
2. å•ä¸ªç¤ºä¾‹æŸ¥è¯¢
3. [æ–°å¢] Type_ID ç‰¹å¾è§£æå¹¶å¯¼å‡ºä¸º JSONL
"""

import duckdb
import os
import time
import pandas as pd
import json

# æ•°æ®åº“è·¯å¾„ (è¯·ç¡®ä¿æ­¤å‰å·²ç”Ÿæˆ .db æ–‡ä»¶)
OUTPUT_DIR = 'output'
DB_FILE = os.path.join(OUTPUT_DIR, 'local_migration_data.db')
JSONL_FILE = os.path.join(OUTPUT_DIR, 'type_features.jsonl')

def query_total_stats(conn):
    """æŸ¥è¯¢æ•°æ®åº“æ€»ä½“ç»Ÿè®¡ä¿¡æ¯"""
    print("\n=== ğŸ“Š æ•°æ®åº“æ€»ä½“æ¦‚è§ˆ ===")
    start_time = time.time()
    
    # èšåˆæŸ¥è¯¢ï¼šæ€»è¡Œæ•°å’Œæ€»äººå£
    query = "SELECT COUNT(*) as total_rows, SUM(Total_Count) as total_pop FROM migration_data"
    result = conn.execute(query).fetchone()
    
    elapsed = time.time() - start_time
    
    print(f"æ€»è¡Œæ•°:   {result[0]:,}")
    print(f"æ€»äººå£æ•°: {result[1]:,}")
    print(f"æŸ¥è¯¢è€—æ—¶: {elapsed:.4f} ç§’")

def query_sample_city(conn, city_name="åŒ—äº¬", year=2024, month=3, limit=500):
    """ç¤ºä¾‹æŸ¥è¯¢ï¼šè·å–æŒ‡å®šåŸå¸‚æŒ‡å®šå¹´æœˆçš„ä¸åŒTypeæ•°æ®"""
    print(f"\n=== ğŸ” ç¤ºä¾‹æŸ¥è¯¢: {year}å¹´{month}æœˆæ¥æºåŸå¸‚åŒ…å« '{city_name}' (å‰{limit}æ¡) ===")
    start_time = time.time()
    
    # å‚æ•°åŒ–æŸ¥è¯¢ï¼Œæ˜¾ç¤ºTypeã€æ€»æ•°ã€ç›®æ ‡åŸå¸‚å’Œæ¦‚ç‡
    sql = """
    SELECT Year, Month, Type_ID, From_City, Total_Count, Stay_Prob,
           To_Top1, To_Top1_Prob, To_Top2, To_Top2_Prob, To_Top3, To_Top3_Prob
    FROM migration_data 
    WHERE From_City LIKE ? AND Year = ? AND Month = ?
    ORDER BY Total_Count DESC
    LIMIT ?
    """
    
    # DuckDB å¯ä»¥ç›´æ¥è¿”å› Pandas DataFrameï¼Œæ‰“å°éå¸¸ç¾è§‚
    df = conn.execute(sql, [f'%{city_name}%', year, month, limit]).df()
    
    elapsed = time.time() - start_time
    
    if df.empty:
        print("æœªæ‰¾åˆ°åŒ¹é…æ•°æ®ã€‚")
    else:
        print(f"æ‰¾åˆ° {len(df)} æ¡è®°å½•:")
        print(f"æ€»äººå£æ•°: {df['Total_Count'].sum():,}")
        print("-" * 120)
        # to_string(index=False) éšè— pandas çš„ç´¢å¼•åˆ—ï¼Œä½¿è¾“å‡ºæ›´å¹²å‡€
        print(df.to_string(index=False))
    
    print(f"\næŸ¥è¯¢è€—æ—¶: {elapsed:.4f} ç§’")

def extract_type_features(conn):
    """
    [æ–°å¢åŠŸèƒ½] æå–æ‰€æœ‰å”¯ä¸€çš„ Type_IDï¼Œè§£æä¸º 6 ä¸ªç»´åº¦ï¼Œå¹¶ä¿å­˜ä¸º JSONL
    """
    print(f"\n=== ğŸ§¬ æ­£åœ¨æå– Type_ID ç‰¹å¾åˆ° {JSONL_FILE} ===")
    start_time = time.time()

    # 1. è·å–æ‰€æœ‰å”¯ä¸€çš„ Type_IDï¼ŒæŒ‰å­—æ¯å‡åºæ’åˆ—
    # ä½¿ç”¨ DISTINCT ç¡®ä¿å”¯ä¸€æ€§
    types_list = conn.execute("SELECT DISTINCT Type_ID FROM migration_data ORDER BY Type_ID ASC").fetchall()
    
    print(f"å‘ç° {len(types_list)} ä¸ªå”¯ä¸€çš„ Type IDã€‚å¼€å§‹è§£æ...")

    # ç»´åº¦å®šä¹‰ï¼ˆä»…ä½œå‚è€ƒï¼Œç”¨äºä»£ç é€»è¾‘å¯¹ç…§ï¼‰
    # D1: gender (M/F)
    # D2: lifecycle (16-24/25-34...)
    # D3: education (EduLo/EduMid...)
    # D4: industry (Mfg/Service...)
    # D5: income (IncL/IncM...)
    # D6: family_status (Split/Unit)

    count = 0
    with open(JSONL_FILE, 'w', encoding='utf-8') as f:
        for t in types_list:
            type_id = t[0]
            parts = type_id.split('_')

            # ç¡®ä¿åˆ‡åˆ†å‡º 6 ä¸ªéƒ¨åˆ†ï¼Œé˜²æ­¢æ•°æ®å¼‚å¸¸å¯¼è‡´æŠ¥é”™
            if len(parts) == 6:
                feature_dict = {
                    "type": type_id,          # åŸå§‹ ID
                    "gender": parts[0],          # D1: æ€§åˆ«
                    "age": parts[1],       # D2: ç”Ÿå‘½å‘¨æœŸ (å¹´é¾„æ®µ)
                    "edu": parts[2],       # D3: å­¦å†
                    "job": parts[3],        # D4: è¡Œä¸šèµ›é“
                    "income": parts[4],          # D5: ç›¸å¯¹æ”¶å…¥
                    "family": parts[5]    # D6: å®¶åº­çŠ¶æ€
                }
                
                # å†™å…¥ JSONL (ä¸€è¡Œä¸€ä¸ª JSON å¯¹è±¡)
                f.write(json.dumps(feature_dict, ensure_ascii=False) + '\n')
                count += 1
            else:
                print(f"[WARN] è·³è¿‡æ ¼å¼å¼‚å¸¸çš„ ID: {type_id}")

    elapsed = time.time() - start_time
    print(f"âœ… æˆåŠŸå¯¼å‡º {count} æ¡ç‰¹å¾è®°å½•ã€‚")
    print(f"è€—æ—¶: {elapsed:.4f} ç§’")

if __name__ == "__main__":
    if not os.path.exists(DB_FILE):
        print(f"é”™è¯¯: æ•°æ®åº“æ–‡ä»¶ {DB_FILE} ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œç”Ÿæˆè„šæœ¬ã€‚")
    else:
        try:
            # å»ºç«‹è¿æ¥ (read_only=True æ›´å®‰å…¨ä¸”æ”¯æŒå¹¶å‘è¯»å–)
            with duckdb.connect(DB_FILE, read_only=True) as conn:
                # 1. æŸ¥è¯¢æ€»æ•°
                query_total_stats(conn)
                
                # 2. æ‰§è¡Œä¸€ä¸ªç¤ºä¾‹æŸ¥è¯¢
                query_sample_city(conn, "å®æ³¢")

                # 3. [æ–°å¢] æå–å¹¶è§£æ Type_ID
                extract_type_features(conn)
                
        except Exception as e:
            print(f"å‘ç”Ÿé”™è¯¯: {e}")